
类似 Hadoop MapReduce 的计算引擎，Spark 启用了内存分布数据集，
由 java,scala 混合编程实现、核心是 scala 编写。
批处理。


- [apache spark](https://spark.apache.org/)

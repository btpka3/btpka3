- [kubernetes](https://kubernetes.io/)
- kubernetes: [å…¥é—¨/ç”Ÿäº§ç¯å¢ƒ](https://kubernetes.io/zh-cn/docs/setup/production-environment/)
    - [kubeadm](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/)
    - [kubespray](https://github.com/kubernetes-sigs/kubespray) ç­‰åŒäºé¢„è®¾äº†ä¸€äº› ansible çš„é…ç½®æ–‡ä»¶ã€‚
    - [kops](https://github.com/kubernetes/kops) : ç®€åŒ–åœ¨äº‘å‚å•†ä¸Šåˆ›å»º k8s é›†ç¾¤
    - [Kubespray vs. Kops vs. kubeadm](https://github.com/kubernetes-sigs/kubespray/blob/master/docs/comparisons.md)
- kuboard.cn: [ä½¿ç”¨ KuboardSpray å®‰è£…kubernetes_v1.23.1:å†å²æ–‡æ¡£](https://kuboard.cn/install/install-k8s.html#kuboard-spray)
- [CNCF: Cloud Native Computing Fundation](https://www.cncf.io/)
- [Helm](https://helm.sh/docs/topics/charts/)
- [Kubernetes API](https://kubernetes.io/docs/reference/kubernetes-api/)
- [kind : K8s in docker](https://kind.sigs.k8s.io/)
- [Minikube](https://kubernetes.io/docs/tutorials/hello-minikube/)
- [moby/hyperkit](https://github.com/moby/hyperkit)
- [killercoda.com](https://killercoda.com/playgrounds/scenario/kubernetes)
- [CKA: Certified Kubernetes Administrator](https://www.cncf.io/certification/cka/) : Kubernetes ç®¡ç†å‘˜è®¤è¯
- [CKAD: Certified Kubernetes Application Developer](https://www.cncf.io/certification/ckad/) :  Kubernetes åº”ç”¨ç¨‹åºå¼€å‘äººå‘˜è®¤è¯
- [CKS: Certified Kubernetes Security Specialist](https://www.cncf.io/certification/cks/) :  Kubernetes åº”ç”¨ç¨‹åºå¼€å‘äººå‘˜è®¤è¯
- kubernetes SIG : kubernetes Special Interest Group
- java:
  - client
    - å®˜æ–¹java client [io.kubernetes:client-java](https://github.com/kubernetes-client/java)
    - [~~fabric8~~](https://fabric8.io/)  # å·²åºŸå¼ƒ
  - Maven plugin
    - [~~fabric8-maven-plugin~~](https://maven.fabric8.io/) # å·²åºŸå¼ƒ
    - eclipse jkube : [kubernetes-maven-plugin](https://github.com/eclipse/jkube)
    -
- [istio.io](https://istio.io/latest/zh/docs/concepts/traffic-management/)
- [k3s](https://k3s.io/)
- [k3d](https://k3d.io/)
- [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/)
- [higress](https://github.com/alibaba/higress)
- [OpenKruise](https://openkruise.io/docs/user-manuals/cloneset/)
- [K8Sé›†ç¾¤å†…Podå¦‚ä½•ä¸æœ¬åœ°ç½‘ç»œæ‰“é€šå®ç°debug](https://cloud.tencent.com/developer/article/1836304)
- [Telepresence](https://github.com/telepresenceio/telepresence)  # ä¸ªäººå¼€å‘æœºä¸k8sé›†ç¾¤ç½‘ç»œäº’è”
- [Ambassador Cloud](https://www.getambassador.io/products/ambassador-cloud)
- [killercoda](https://killercoda.com/account/membership) # äº¤äº’å¼å­¦ä¹ 
- é˜¿é‡Œäº‘
    - [è·å–é›†ç¾¤KubeConfigå¹¶é€šè¿‡kubectlå·¥å…·è¿æ¥é›†ç¾¤](https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/obtain-the-kubeconfig-file-of-a-cluster-and-use-kubectl-to-connect-to-the-cluster?spm=a2c4g.11186623.0.0.33097961DQ7rje)

```yaml
# application/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
    name: nginx-deployment
spec:
    selector:
        matchLabels:
            app: nginx
    replicas: 2
    template:
        metadata:
            labels:
                app: nginx
        spec:
            containers:
                - name: nginx
                  image: nginx:1.14.2
                  ports:
                      - containerPort: 80
```

# context, config
```shell
# å¦‚æœæœ‰å¤šä¸ª k8s é›†ç¾¤ï¼Œæ¯”å¦‚ minikube, kind, æˆ–è€… è¿œç¨‹k8sé›†ç¾¤
# ä¼šæœ‰å¤šä¸ª context ï¼Œ å³ ~/.kube ç›®å½•ä¸‹æœ‰å¤šä¸ªé…ç½®æ–‡ä»¶
# å¯ä»¥é€šè¿‡è¯¥å‘½ä»¤æŸ¥çœ‹
kubectl config get-contexts

# å¯ä»¥é€šè¿‡è¯¥å‘½ä»¤åˆ‡æ¢
kubectl config use-context kind-kind

kubectl config view

# ç¡®ä¿ä¸‹é¢å‘½ä»¤èƒ½åˆ—å‡ºè¯¥è¡¨æ ¼ä¸­å·²ç»å¯ç”¨çš„ æœºå™¨åˆ—è¡¨
kubectl --kubeconfig ~/.kube/config_daily get node

# å¦‚æœä¸æƒ³æ¯æ¬¡éƒ½æŒ‡å®š --kubeconfig å‚æ•°ï¼Œå¯ä»¥è®¾ç½®ä¸‹ç¯å¢ƒå˜é‡ KUBECONFIG
export KUBECONFIG=~/.kube/config_daily

```




```shell
brew install hyperkit
brew install minikube
# automatically selected the hyperkit driver. Other choices: qemu2, virtualbox, ssh, podman (experimental)
# ğŸ„  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

brew install kubernetes-cli
brew install kind
brew install k3d  # k3s

kubectl apply -f https://k8s.io/examples/application/deployment.yaml
```

# é“¾æ¥åˆ°æ—¢æœ‰K8Sé›†ç¾¤

```shell
# k8sé›†ç¾¤é…ç½®ä¿¡æ¯ï¼š
scp root@11.164.234.212:/root/.kube/config ~/.kube/config_daily

# ç¡®ä¿ä¸‹é¢å‘½ä»¤èƒ½åˆ—å‡ºè¯¥è¡¨æ ¼ä¸­å·²ç»å¯ç”¨çš„ æœºå™¨åˆ—è¡¨
kubectl --kubeconfig ~/.kube/config_daily get node

# å¦‚æœä¸æƒ³æ¯æ¬¡éƒ½æŒ‡å®š --kubeconfig å‚æ•°ï¼Œå¯ä»¥è®¾ç½®ä¸‹ç¯å¢ƒå˜é‡ KUBECONFIG
export KUBECONFIG=~/.kube/config_daily
kubectl get node

# é”™è¯¯: ImagePullBackOff : é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è¯¦æƒ…
kubectl describe pod mtee3-deployment-774f644856-j8ghp
```


# statefulset

```shell
kubectl delete statefulset nacos
kubectl get statefulset nacos

kubectl rollout restart deployment <deployment-name>
kubectl rollout restart statefulset <statefulset-name>
kubectl scale --replicas=2 statefulset <statefulset-name>
kubectl get pod -o wide --selector app=nacos

https://www.coder.work/article/7315538
```


# å‘½å
"nginx-deployment-66f8758855-5qtqg"
- "nginx-deployment" : Deployment åç§°
- "66f8758855"       : ReplicaSet åç§°
- "5qtqg"            :



# Hello MiniKube

```shell

minikube ssh

minikube start --container-runtime=cri-o
minikube addons enable metrics-server
minikube -p minikube podman-env
eval $(minikube -p minikube podman-env)

minikube dashboard

kubectl get nodes

kubectl create deployment hello-node --image=registry.k8s.io/e2e-test-images/agnhost:2.39 -- /agnhost netexec --http-port=8080
kubectl get deployments
kubectl get replicasets
kubectl delete deployment nginx-deployment

kubectl get pods
kubectl describe pods

kubectl get events
kubectl config view

kubectl get endpointslices

kubectl expose deployment hello-node --type=LoadBalancer --port=8080
kubectl get services
minikube service hello-node
kubectl delete service jkube-maven-sample-zero-config

kubectl get endpointslices


minikube addons list
minikube addons enable metrics-server
kubectl get pod,svc -n kube-system
minikube addons disable metrics-server

kubectl delete service hello-node
kubectl delete deployment hello-node

minikube stop

# Optional
minikube delete


kubectl plugin list
```


# æ¦‚å¿µ

## Pod
å½“åˆ›å»ºä¸€ä¸ª Deployment æ—¶ï¼Œ K8s åˆ›å»ºä¸€ä¸ª Pod æ¥æŒæœ‰åº”ç”¨å®ä¾‹ã€‚
ä¸€ä¸ª Pod ä»£è¡¨ï¼š
- ä¸€ç»„ åº”ç”¨å®¹å™¨ï¼ˆ1ä¸ªæˆ–å¤šä¸ªï¼‰
- ä»¥åŠè¿™ä¸€ç»„å®¹å™¨é—´å…±äº«çš„èµ„æº
  - Shared storage, as Volumes
  - Networking, as a unique cluster IP address
  - Information about how to run each container, such as the container image version or specific ports to use

## Node
Pod æ€»æ˜¯è¿è¡Œåœ¨ Node ä¸Šã€‚Node åœ¨K8sä¸­å¯ä»¥æ˜¯ä¸€ä¸ª è™šæ‹Ÿæœº ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªç‰©ç†æœºã€‚



# KIND

```shell
kind create cluster
kind get clusters
kubectl cluster-info --context kind-kind
```


# error
ImagePullBackOff



# secret

```plain
Opaque	                                ç”¨æˆ·å®šä¹‰çš„ä»»æ„æ•°æ®
kubernetes.io/service-account-token	    æœåŠ¡è´¦å·ä»¤ç‰Œ
kubernetes.io/dockercfg	                ~/.dockercfg æ–‡ä»¶çš„åºåˆ—åŒ–å½¢å¼
kubernetes.io/dockerconfigjson	        ~/.docker/config.json æ–‡ä»¶çš„åºåˆ—åŒ–å½¢å¼
kubernetes.io/basic-auth	            ç”¨äºåŸºæœ¬èº«ä»½è®¤è¯çš„å‡­æ®
kubernetes.io/ssh-auth	                ç”¨äº SSH èº«ä»½è®¤è¯çš„å‡­æ®
kubernetes.io/tls	                    ç”¨äº TLS å®¢æˆ·ç«¯æˆ–è€…æœåŠ¡å™¨ç«¯çš„æ•°æ®
bootstrap.kubernetes.io/token	        å¯åŠ¨å¼•å¯¼ä»¤ç‰Œæ•°æ®
```


## ç±»å‹



## åˆ›å»º-é€šè¿‡ kubectl å‘½ä»¤

```shell
kubectl create secret \
    docker-registry yourSecretName \
    --docker-server=registry.your.com \
    --docker-username=zhang3 \
    --docker-password=xxxPassword

kubectl describe secret yourSecretName
kubectl get      secret yourSecretName -o yaml
kubectl get      secret yourSecretName -o jsonpath="{.data['\.dockerconfigjson']}" | base64 -d | jq
kubectl get      secret yourSecretName -o custom-columns=NAME:.data.'\.dockerconfigjson'
```

```json
{
  "auths": {
    "registry.xxx.com": {
      "username": "zhang3@xxx.com",
      "password": "xxxPassword",
      "email": "zhang3@xxx.com",
      "auth": "xxxBase64xxx"
    }
  }
}
```

## åˆ›å»º-é€šè¿‡ yaml æ–‡ä»¶

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
# base64 ç¼–ç 
data:
  username: YWRtaW4=
  password: MTIzNDU2Cg==
# æ˜æ–‡
# ç›¸åŒçš„ key å‡ºç°åœ¨ stringData, data ä¸­æ—¶ï¼Œ åˆ™ä½¿ç”¨ stringData ä¸­çš„å€¼
stringData:
  username: admin
  password: "123456"
```


## ä½¿ç”¨
- ä½œä¸ºæŒ‚è½½åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ä¸Šçš„å· ä¸­çš„æ–‡ä»¶ã€‚
- ä½œä¸ºå®¹å™¨çš„ç¯å¢ƒå˜é‡
- ç”± kubelet åœ¨ä¸º Pod æ‹‰å–é•œåƒæ—¶ä½¿ç”¨ã€‚

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: mypod
      image: redis
      volumeMounts:
        - name: foo
          mountPath: "/etc/foo"
          readOnly: true
  volumes:
   - name: foo
     secret:
       secretName: mysecret
       optional: true
```

# ConfigMap

## é€šè¿‡ yaml å®šä¹‰

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: game-demo
data:
  # property-like keys; each key maps to a simple value
  player_initial_lives: "3"
  ui_properties_file_name: "user-interface.properties"

  # file-like keys
  game.properties: |
    enemy.types=aliens,monsters
    player.maximum-lives=5
  user-interface.properties: |
    color.good=purple
    color.bad=yellow
    allow.textmode=true
```

```shell
kubectl apply -f xxx.yaml
kubectl -n default get configmap game-demo
# æŸ¥çœ‹ configMap çš„ å†…å®¹
kubectl -n default describe configmap game-demo
# è¿è¡Œæ€ç¼–è¾‘ configMap
kubectl -n default edit configmap game-demo
```


## ä½¿ç”¨
- ä½œä¸ºå®¹å™¨çš„å‘½ä»¤å’Œå‚æ•°
- ä½œä¸ºå®¹å™¨çš„ç¯å¢ƒå˜é‡
- å°†å…¶ä½œä¸ºåªè¯»æ•°æ®å·ä¸­çš„æ–‡ä»¶æŒ‚è½½
- åœ¨å®¹å™¨ä¸­é€šè¿‡ k8s API è¯»å–å…¶å†…å®¹

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: configmap-demo-pod
spec:
  containers:
    - name: demo
      image: alpine
      command: ["sleep", "3600"]
      env:
        # Define the environment variable
        - name: PLAYER_INITIAL_LIVES # Notice that the case is different here
                                     # from the key name in the ConfigMap.
          valueFrom:
            configMapKeyRef:
              name: game-demo           # The ConfigMap this value comes from.
              key: player_initial_lives # The key to fetch.
        - name: UI_PROPERTIES_FILE_NAME
          valueFrom:
            configMapKeyRef:
              name: game-demo
              key: ui_properties_file_name
      volumeMounts:
        - name: config
          mountPath: "/config"
          readOnly: true
  volumes:
    - name: config
      configMap:
        # Provide the name of the ConfigMap you want to mount.
        name: game-demo
        # An array of keys from the ConfigMap to create as files
        items:
          - key: "game.properties"
            path: "game.properties"
          - key: "user-interface.properties"
            path: "user-interface.properties"
```


# volume/storage


## PersistentVolume : PV



```shell
kubectl get pv
# Status : Bound/åœ¨ç”¨
# Claim  : æ˜¯ç”±å“ªä¸ª PersistentVolumeClaim åˆ›å»ºçš„
kubectl describe pv pvc-5d62783b-7720-43a2-add3-8204d61120d9
```

- ReadWriteOnce:



```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0003
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: slow
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /tmp
    server: 172.17.0.2
```

## PersistentVolumeClaim : PVC

```shell
kubectl get pvc
# æ£€æŸ¥
# Status  : Bound/åœ¨ç”¨
# Used By : è¢«å“ªä¸ªpodä½¿ç”¨
kubectl describe pvc blackcat-data-blackcat-0
```


# event

```shell
kubectl get event
kubectl get event  --field-selector involvedObject.name=nacos-2 --sort-by=".metadata.managedFields[0].time"
kubectl logs nacos-2
```


# namespace

```shell
kubectl create ns xxxNameSpace
kubectl get ns
```

# sc : storage class

```shell
kubectl get sc
```

# kubelet



# controller

```shell
# æ£€æŸ¥æ‰€æœ‰pod
kubectl get pods --all-namespaces
```


# service

domain: `${serviceName}.${namespace}.svc.cluster.local`
ç¤ºä¾‹ï¼š my-service.prod.svc.cluster.local

## service NodePort


```shell
# è·å– æ‰€æœ‰ type=NodePort çš„ service ä¿¡æ¯
kubectl get service -o json | jq -r '
    def to_port: (.port|tostring) + ":" + (.nodePort|tostring) + "/" + (.protocol|tostring);

    ["NAME", "TYPE", "CLUSTER-IP", "PORT(S)", "SELECTOR"],
    (
       .items[]
       | select(.spec.type=="NodePort")
       | [
          .metadata.name,
          .spec.type,
          .spec.clusterIP,
          (.spec.ports|map(.|to_port)|join(",")),
          (.spec.selector|to_entries|map(.key + "=" + .value)|join(","))
         ]
    )
    | @tsv
' | column -ts $'\t'
```


# addon

```shell
# è·å–æ‰€æœ‰ k8s çš„ pod
kubectl get pod -n kube-system
kubectl get service -n kube-system
```

## coreDns
æ¨èä½¿ç”¨ helm æ–¹å¼å®‰è£… , ä» k8s 1.21 å¼€å§‹ï¼Œä¸å†æ”¯æŒ kube-dns
https://github.com/coredns/helm


# ephemeral containers / ä¸´æ—¶å®¹å™¨
[è°ƒè¯•è¿è¡Œä¸­çš„ Pod](https://kubernetes.io/zh-cn/docs/tasks/debug/debug-application/debug-running-pod/)


```shell
kubectl run ephemeral-demo --image=registry.k8s.io/pause:3.1 --restart=Never
# ä»¥ä¸‹å‘½ä»¤å°†æŠ¥é”™
kubectl exec -it ephemeral-demo -- sh
# è¿›è¡Œ debug
kubectl debug -it ephemeral-demo --image=busybox:1.28 --image-pull-policy=IfNotPresent --target=ephemeral-demo
```




# install on alpine
https://dev.to/xphoniex/how-to-create-a-kubernetes-cluster-on-alpine-linux-kcg

```shell
echo "@community http://dl-cdn.alpinelinux.org/alpine/edge/community/" >> /etc/apk/repositories
echo "@testing http://dl-cdn.alpinelinux.org/alpine/edge/testing/"     >> /etc/apk/repositories

apk add kubernetes@testing
apk add docker@community
apk add cni-plugins@testing
```

# install on fedora

- [å®‰è£… kubeadm](https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
- [How to install Kubernetes cluster on CentOS 8](https://upcloud.com/resources/tutorials/install-kubernetes-cluster-centos-8)

## å‡†å¤‡æ“ä½œç³»ç»Ÿ
```shell
docker run --rm docker.io/library/fedora:38 cat /etc/os-release
docker run --name my-k8s-master -it docker.io/library/fedora:38 bash -l
docker ps -a
docker exec -it my-k8s-master bash -l
```

## å®‰è£…

### åœ¨æ‰€æœ‰Masterã€Worker ä¸Šéƒ½å‡†å¤‡å¥½åˆå§‹åŒ–å·¥ä½œ
```shell
cat /etc/os-release

dnf repolist
dnf -y upgrade

# disable SELinux enforcement
setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux

# å…è®¸é€æ˜ä¼ªè£…ï¼Œæ–¹ä¾¿ k8s pod ä¹‹é—´çš„ Virtual Extensible LAN (VxLAN) æµé‡
dnf install kmod
modprobe br_netfilter

# å…è®¸ ip ä¼ªè£…
dnf install firewalld
firewall-cmd --add-masquerade --permanent
firewall-cmd --reload

# Set bridged packets to traverse iptables rules.
dnf install procps-ng
mkdir -p /etc/sysctl.d
cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl --system

# ç¦ç”¨å†…å­˜äº¤æ¢ï¼Œä»¥æé«˜æ€§èƒ½
swapoff -a
```

### åœ¨æ‰€æœ‰Masterã€Worker ä¸Šéƒ½å®‰è£…docker
[Install Docker Engine on Fedora](https://docs.docker.com/engine/install/fedora/#prerequisites)

```shell
# åˆ é™¤æ—§çš„å®‰è£…
dnf remove \
        docker \
        docker-client \
        docker-client-latest \
        docker-common \
        docker-latest \
        docker-latest-logrotate \
        docker-logrotate \
        docker-selinux \
        docker-engine-selinux \
        docker-engine

dnf install dnf-plugins-core
dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo

dnf install \
        docker-ce \
        docker-ce-cli \
        containerd.io \
        docker-buildx-plugin \
        docker-compose-plugin

systemctl start docker
docker run hello-world

docker version
docker images
```

## åœ¨æ‰€æœ‰Masterã€Worker ä¸Šéƒ½å®‰è£… kubernetes

https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/

```shell
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable --now kubelet
```


# Job


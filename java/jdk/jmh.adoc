* link:https://github.com/openjdk/jmh[openjdk/jmh]
* link:https://cloud.tencent.com/developer/article/2100295[JMH使用指南[通俗易懂\]]
* link:https://search.maven.org/search?q=g:org.openjdk.jmh%20AND%20a:jmh-java-benchmark-archetype[jmh-java-benchmark-archetype]

[source,shell]
----
# 注意: groupId,artifactId,version 是 jmh-java-benchmark-archetype 的模板中使用的变量
% mvn archetype:generate \
  -DinteractiveMode=false \
  -DarchetypeGroupId=org.openjdk.jmh \
  -DarchetypeArtifactId=jmh-java-benchmark-archetype \
  -DarchetypeVersion=1.37 \
  -DgroupId=me.test \
  -DartifactId=my-jmh \
  -Dversion=1.0


#

mvn dependency:get -Dartifact=org.openjdk.jmh:jmh-core:1.37
mvn dependency:get -Dartifact=org.openjdk.jmh:jmh-generator-annprocess:1.37

alias jmh="java -cp \
${HOME}/.m2/repository/org/openjdk/jmh/jmh-core/1.37/jmh-core-1.37.jar\
:${HOME}/.m2/repository/org/openjdk/jmh/jmh-generator-annprocess/1.37/jmh-generator-annprocess-1.37.jar\
:${HOME}/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar\
:${HOME}/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar\
 org.openjdk.jmh.Main"

# 输出命令行帮助文档
% jmh -h
# 列出可以被机器识别的结果格式
# 示例输出:
# Available formats: text, csv, scsv, json, latex
% jmh -lrf

# 列出 profiler
% sudo echo "先执行下sudo，后续命令内部有可能会执行sudo操作，避免密码提示"
% jmh -lprof
Supported profilers:
          cl: Classloader profiling via standard MBeans
        comp: JIT compiler profiling via standard MBeans
   dtraceasm: DTrace profile provider + PrintAssembly Profiler
          gc: GC profiling via standard MBeans
         jfr: Java Flight Recorder profiler
     mempool: Memory pool/footprint profiling via standard MBeans
      pauses: Pauses profiler
  safepoints: Safepoints profiler
       stack: Simple and naive Java stack profiler

Unsupported profilers:
       async: <none>
Unable to load async-profiler. Ensure asyncProfiler library is on LD_LIBRARY_PATH (Linux), DYLD_LIBRARY_PATH (Mac OS), or -Djava.library.path. Alternatively, point to explicit library location with -prof async:libPath=<path>.
        perf: <none>
[Cannot run program "perf": error=2, No such file or directory]
     perfasm: <none>
[Cannot run program "perf": error=2, No such file or directory]
     perfc2c: <none>
[Cannot run program "perf": error=2, No such file or directory]
    perfnorm: <none>
[Cannot run program "perf": error=2, No such file or directory]
    xperfasm: <none>
Unable to start the profiler. Try running JMH as Administrator, and ensure that previous profiling session is stopped. Use 'xperf -stop' to stop the active profiling session.: [Cannot run program "xperf": error=2, No such file or directory]

----

`jmh -h` 输出的帮助文档：

[source,txt]
----
Usage: java -jar ... [regexp*] [options]
 [opt] means optional argument.
 <opt> means required argument.
 "+" means comma-separated list of values.
 "time" arguments accept time suffixes, like "100ms".

Command line options usually take precedence over annotations.

  [arguments]                 Benchmarks to run (regexp+). (default: .*)

  -i <int>                    Number of measurement iterations to do. Measurement
                              iterations are counted towards the benchmark score.
                              (default: 1 for SingleShotTime, and 5 for all other
                              modes)

  -bs <int>                   Batch size: number of benchmark method calls per
                              operation. Some benchmark modes may ignore this
                              setting, please check this separately. (default:
                              1)

  -r <time>                   Minimum time to spend at each measurement iteration.
                              Benchmarks may generally run longer than iteration
                              duration. (default: 10 s)

  -wi <int>                   Number of warmup iterations to do. Warmup iterations
                              are not counted towards the benchmark score. (default:
                              0 for SingleShotTime, and 5 for all other modes)

  -wbs <int>                  Warmup batch size: number of benchmark method calls
                              per operation. Some benchmark modes may ignore this
                              setting. (default: 1)

  -w <time>                   Minimum time to spend at each warmup iteration. Benchmarks
                              may generally run longer than iteration duration.
                              (default: 10 s)

  -to <time>                  Timeout for benchmark iteration. After reaching
                              this timeout, JMH will try to interrupt the running
                              tasks. Non-cooperating benchmarks may ignore this
                              timeout. (default: 10 min)

  -t <int>                    Number of worker threads to run with. 'max' means
                              the maximum number of hardware threads available
                              on the machine, figured out by JMH itself. (default:
                              1)

  -bm <mode>                  Benchmark mode. Available modes are: [Throughput/thrpt,
                              AverageTime/avgt, SampleTime/sample, SingleShotTime/ss,
                              All/all]. (default: Throughput)

  -si <bool>                  Should JMH synchronize iterations? This would significantly
                              lower the noise in multithreaded tests, by making
                              sure the measured part happens only when all workers
                              are running. (default: true)

  -gc <bool>                  Should JMH force GC between iterations? Forcing
                              the GC may help to lower the noise in GC-heavy benchmarks,
                              at the expense of jeopardizing GC ergonomics decisions.
                              Use with care. (default: false)

  -foe <bool>                 Should JMH fail immediately if any benchmark had
                              experienced an unrecoverable error? This helps
                              to make quick sanity tests for benchmark suites,
                              as well as make the automated runs with checking error
                              codes. (default: false)

  -v <mode>                   Verbosity mode. Available modes are: [SILENT, NORMAL,
                              EXTRA]. (default: NORMAL)

  -f <int>                    How many times to fork a single benchmark. Use 0 to
                              disable forking altogether. Warning: disabling
                              forking may have detrimental impact on benchmark
                              and infrastructure reliability, you might want
                              to use different warmup mode instead. (default:
                              5)

  -wf <int>                   How many warmup forks to make for a single benchmark.
                              All iterations within the warmup fork are not counted
                              towards the benchmark score. Use 0 to disable warmup
                              forks. (default: 0)

  -o <filename>               Redirect human-readable output to a given file.

  -rff <filename>             Write machine-readable results to a given file.
                              The file format is controlled by -rf option. Please
                              see the list of result formats for available formats.
                              (default: jmh-result.<result-format>)

  -prof <profiler>            Use profilers to collect additional benchmark data.
                              Some profilers are not available on all JVMs and/or
                              all OSes. Please see the list of available profilers
                              with -lprof.

  -tg <int+>                  Override thread group distribution for asymmetric
                              benchmarks. This option expects a comma-separated
                              list of thread counts within the group. See @Group/@GroupThreads
                              Javadoc for more information.

  -jvm <string>               Use given JVM for runs. This option only affects forked
                              runs.

  -jvmArgs <string>           Use given JVM arguments. Most options are inherited
                              from the host VM options, but in some cases you want
                              to pass the options only to a forked VM. Either single
                              space-separated option line, or multiple options
                              are accepted. This option only affects forked runs.

  -jvmArgsAppend <string>     Same as jvmArgs, but append these options after the
                              already given JVM args.

  -jvmArgsPrepend <string>    Same as jvmArgs, but prepend these options before
                              the already given JVM arg.

  -tu <TU>                    Override time unit in benchmark results. Available
                              time units are: [m, s, ms, us, ns]. (default: SECONDS)

  -opi <int>                  Override operations per invocation, see @OperationsPerInvocation
                              Javadoc for details. (default: 1)

  -rf <type>                  Format type for machine-readable results. These
                              results are written to a separate file (see -rff).
                              See the list of available result formats with -lrf.
                              (default: CSV)

  -wm <mode>                  Warmup mode for warming up selected benchmarks.
                              Warmup modes are: INDI = Warmup each benchmark individually,
                              then measure it. BULK = Warmup all benchmarks first,
                              then do all the measurements. BULK_INDI = Warmup
                              all benchmarks first, then re-warmup each benchmark
                              individually, then measure it. (default: INDI)

  -e <regexp+>                Benchmarks to exclude from the run.

  -p <param={v,}*>            Benchmark parameters. This option is expected to
                              be used once per parameter. Parameter name and parameter
                              values should be separated with equals sign. Parameter
                              values should be separated with commas.

  -wmb <regexp+>              Warmup benchmarks to include in the run in addition
                              to already selected by the primary filters. Harness
                              will not measure these benchmarks, but only use them
                              for the warmup.

  -l                          List the benchmarks that match a filter, and exit.

  -lp                         List the benchmarks that match a filter, along with
                              parameters, and exit.

  -lrf                        List machine-readable result formats, and exit.

  -lprof                      List profilers, and exit.

  -h                          Display help, and exit.
----

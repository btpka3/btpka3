


## DataWorks
* link:https://help.aliyun.com/zh/dataworks/product-overview/what-is-dataworks[什么是DataWorks]

## MaxCompute/ODPS
*  阿里云 link:https://www.aliyun.com/product/odps[云原生大数据计算服务 MaxCompute]
* link:https://help.aliyun.com/zh/maxcompute/product-overview/what-is-maxcompute[什么是MaxCompute]
* link:https://help.aliyun.com/zh/maxcompute/user-guide/what-is-maxcompute-studio[认识MaxCompute Studio]
* link:https://help.aliyun.com/zh/maxcompute/user-guide/maxcompute-v2-0-data-type-edition[2.0数据类型版本]
* link:https://help.aliyun.com/zh/maxcompute/user-guide/table-operations-1[DDL]
* link:https://help.aliyun.com/zh/maxcompute/user-guide/insert-operation-1/[DML]
** link:https://help.aliyun.com/zh/maxcompute/user-guide/insert-or-update-data-into-a-table-or-a-static-partition[INSERT INTO | INSERT OVERWRITE]
** link:https://help.aliyun.com/zh/maxcompute/user-guide/common-table-expressions[COMMON TABLE EXPRESSION（CTE）]
* link:https://help.aliyun.com/zh/maxcompute/user-guide/endpoints[Endpoint]

** link:https://help.aliyun.com/zh/maxcompute/user-guide/mappings-between-built-in-functions-of-maxcompute-and-built-in-functions-of-hive-mysql-and-oracle[与Hive、MySQL、Oracle内建函数对照表]

* link:https://help.aliyun.com/zh/dataworks/developer-reference/api-dataworks-public-2020-05-18-getmetatablecolumn[GetMetaTableColumn - 获取表的字段信息]
*  阿里云：云原生大数据计算服务 MaxCompute/操作指南/SDK 参考/Java SDK参考/link:https://help.aliyun.com/zh/maxcompute/user-guide/sdk-for-java[Java SDK介绍]  ： com.aliyun.odps:odps-sdk-core:X.X.X-public
[source,xml]
----
<dependency>
  <groupId>com.aliyun</groupId>
  <artifactId>aliyun-java-sdk-dataworks-public</artifactId>
  <version>3.3.18</version>
</dependency>
<dependency>
  <groupId>com.aliyun.odps</groupId>
  <artifactId>odps-sdk-core</artifactId>
  <version>X.X.X-public</version>
</dependency>
----
## 数据类型

* INT
* BIGINT
* BINARY
* DECIMAL
* VARCHAR
* DATETIME: 无时区, 精精确到毫秒
* TIMESTAMP: 无时区, 精确到纳秒
* TIMESTAMP_NTZ

## 函数
* link:https://help.aliyun.com/zh/maxcompute/user-guide/built-in-functions-1/[内建函数]


* UDF:
** UDF  :  user-defined function : 用户定义函数
** UDAF : user-defined aggregate function : 用户定义聚集函数
** UDTF : user-defined table-generating function : 用户定义表生成函数

### UDTF

[source,sql]
----
-- explode
 select explode(array(
    'aaa',
    'bbb',
    'ccc'
)) as xxx ;
select explode(array(
    datetrunc(DATEADD(cast(current_timestamp()as datetime),-3,'day'),'DD'),
    datetrunc(DATEADD(cast(current_timestamp()as datetime),-2,'day'),'DD'),
    datetrunc(DATEADD(cast(current_timestamp()as datetime),-1,'day'),'DD')
)) as yyy;
-- JSON_EXPLODE
-- JSON_TUPLE
-- trans_array
----

### 窗口函数
* COUNT
### 字符串函数

[source,plain]
----
● CONCAT_WS : 用分隔符拼接字符串:  select CONCAT_WS(',','a','b','c'); ->  a,b,c
● get_json_object ： 按照 json path 提取数据
● UDTF: json_tuple : 一次性从JSON中提取多个key 的值，并转换为列。
● TRANSLATE ： 按照匹配的原字符串长度，替换成目标字符串
----

### 日期函数


[source,sql]
----
select current_timestamp();

select
   to_date('2024071013', 'yyyymmddhh'),
   DATEADD(to_date('2024071013', 'yyyymmddhh'), 1, 'hh');

-- 1.0数据类型
select DATETIME'2017-11-11 21:22:23';

-- 2.0数据类型
select DATETIME'2017-11-11 21:22:23';
select DATE'2017-11-11';
select TIMESTAMP'2017-11-11 00:00:00.123456789'


-- yyyy为4位数的年，mm为2位数的月，dd为2位数的日，hh为24小时制的时，mi为2位数的分钟，ss为2位数秒，ff3为3位精度毫秒。
select to_char(DATETIME'2017-11-11 21:22:23','yyyy-mm-dd');

-- date_add 的返回值是 date 类型
-- 2017-11-10
select date_add(DATETIME'2017-11-11 21:22:23',-1);

-- DATEADD 的返回值是 date|datetime 类型
-- 2017-11-10 21:22:23
select DATEADD(DATETIME'2017-11-11 21:22:23',-1,'day');
select to_char(DATEADD(DATETIME'2017-11-11 21:22:23',-1,'day'), 'yyyy-mm-dd');
select DATEADD(current_timestamp(),-1, 'day') ; -- ❌ 报错，因为入参是timestamp，期望是 Date|dateTime
select DATEADD(NOW(),-1, 'day')                 -- ❌ 报错，因为入参是timestamp，期望是 Date|dateTime
select DATEADD(cast(current_timestamp()as datetime),-1, 'day');  -- ⭕️
select DATEADD(cast(NOW()as datetime),-1, 'day');                -- ⭕️


-- datetrunc 的返回值是 date|datetime 类型
-- 2017-11-11 00:00:00
select datetrunc(DATETIME'2017-11-11 21:22:23', 'DD') ;
select to_char(datetrunc(DATETIME'2017-11-11 21:22:23', 'DD'), 'yyyy-mm-dd');
----

### 复杂类型函数

* from_json: 根据JSON字符串jsonStr和schema信息，返回ARRAY、MAP或STRUCT类型


[source,sql]
----
-- JSON 对象中解析部分字段
-- 适合 TT 扫描JSON日志，并解析大部分字段。
select * from
(
     (select json_tuple('{"a":1}','a','b') as (aaa, bbb))
JOIN (select 'c' as ccc)
);
/* ------ 结果
 aaa | bbb    | ccc
-----+--------+-----
 1   | <null> | c
*/
----

* TO_JSON
### 其他函数
* TRANS_ARRAY ： UDTF:  一行转多行
* TRANS_COLS :  UDTF:  一行转多行
* STACK ： UDTF:  将数组转成N行记录
* DECODE ： 实现 IF...THEN...ELSE
* GET_IDCARD_AGE
* GET_USER_ID : 获取当前阿里云账号 的ID
* MAX_PT ： 返回分区表的一级分区中有数据的分区的最大值
* PARTITION_EXISTS
* TABLE_EXISTS
* SAMPLE



## 示例

* 一条记录转多条

[source,sql]
----
-- 示例1
SELECT
    trans_array(2, ',', t.bizName, t.firstProdName, t.ruleIds)
    as (bizName,firstProdName,ruleId)
from (
    SELECT
        'bizName001'        as bizName,
        'firstProdName001'  as firstProdName,
        'secondProdName001' as secProdName,
        'aaa,bbb,ccc'       as ruleIds
    UNION
    SELECT
        'bizName002'        as bizName,
        'firstProdName002'  as firstProdName,
        'secondProdName002' as secProdName,
        'xxx,yyy,zzz'       as ruleIds
) t;

-- 示例2
select
    trans_array(2, ',', t.bizName, t.firstProdName, t.ruleIds)
    as (bizName,firstProdName,ruleId)
from values
    ('bizName001', 'firstProdName001', 'secondProdName001', 'aaa,bbb,ccc'),
    ('bizName002', 'firstProdName002', 'secondProdName002', 'xxx,yyy,zzz')
as t(bizName,      firstProdName,      secProdName,         ruleIds);
----


示例输出

[source,plain]
----
bizname	    firstprodname	    ruleid
bizName001	firstProdName001	aaa
bizName001	firstProdName001	bbb
bizName001	firstProdName001	ccc
bizName002	firstProdName002	xxx
bizName002	firstProdName002	yyy
bizName002	firstProdName002	zzz
----

* 提取JSON 对象字符串的 keys

[source,sql]
----
-- 输出：R_3632245,R_3511414
select array_join(MAP_KEYS(from_json('{"R_3632245":"38.0","R_3511414":"12.0"}', 'map<string,string>')),',');
----

* 生成JSON字符串

[source,sql]
----
-- 输出： {"a":1,"b":2,"c":null}
to_json(named_struct(
  'a', 1,
  'b', 2 ,
  'c', cast(null as string)  -- 注意：null值需要特殊处理
))
----

* GzipBase64 转码

[source,sql]
----
-- string -> UTF-8 字节数组 -> Gzip -> base64 字符串
-- 输出：H4sIAAAAAAAAA6tWSlSyUkpMTFTSUUpSSrIyAgMdpWQlq7TEnOJUHaUUoHxKSgpQPhXIerax8+na6Uq1APi7hF04AAAA
select BASE64(COMPRESS(ENCODE('{"a":"aaa","b"b:222222,"c":false,"d":"ddd","e":"汉字"}', 'UTF-8')));

-- base64 字符串 -> 字节数组 -> Gzip 解压缩 -> 转换成 UTF-8 string
-- 输出： {"a":"aaa","b"b:222222,"c":false,"d":"ddd","e":"汉字"}
select cast(DECOMPRESS(UNBASE64('H4sIAAAAAAAAAKtWSlSyUkpMTFTSUUpSSrIyAgMdpWQlq7TEnOJUHaUUoHxKSgpQPhXIerax8+na\n6Uq1APi7hF04AAAA')) as string);

-- 统计压缩率
select
length('H4sIAAAAAAAAAKtWSlSyUkpMTFTSUUpSSrIyAgMdpWQlq7TEnOJUHaUUoHxKSgpQPhXIerax8+na\n6Uq1APi7hF04AAAA')
/length(cast(DECOMPRESS(UNBASE64('H4sIAAAAAAAAAKtWSlSyUkpMTFTSUUpSSrIyAgMdpWQlq7TEnOJUHaUUoHxKSgpQPhXIerax8+na\n6Uq1APi7hF04AAAA')) as string)) as rate,
cast(DECOMPRESS(UNBASE64('H4sIAAAAAAAAAKtWSlSyUkpMTFTSUUpSSrIyAgMdpWQlq7TEnOJUHaUUoHxKSgpQPhXIerax8+na\n6Uq1APi7hF04AAAA')) as string) as json
;

----



